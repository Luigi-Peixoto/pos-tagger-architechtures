{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de dependências\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading e pre processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de caminhos dos arquivos de corpus\n",
    "train_file = \"Penn Treebank/Secs0-18 - training\"\n",
    "dev_file   = \"Penn Treebank/Secs19-21 - development\"\n",
    "test_file  = \"Penn Treebank/Secs22-24 - testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Funções de pré-processamento do texto\n",
    "def carregar_corpus(caminho_arquivo: str) -> str:\n",
    "    \"\"\"\n",
    "    Lê o arquivo completo em utf-8 e retorna como string.\n",
    "    \"\"\"\n",
    "    with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def dividir_em_sentencas(texto: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Divide o texto em sentenças, assumindo uma sentença por linha.\n",
    "    \"\"\"\n",
    "    return texto.strip().split(\"\\n\")\n",
    "\n",
    "def processar_sentenca(sentenca: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Separa tokens de formato palavra_TAG em pares (palavra, tag).\n",
    "    Converte para lowercase, exceto nomes próprios (NNP, NNPS).\n",
    "    \"\"\"\n",
    "    tokens = sentenca.strip().split()\n",
    "    pares = []\n",
    "    for token in tokens:\n",
    "        if \"_\" in token:\n",
    "            palavra, tag = token.rsplit(\"_\", 1)\n",
    "            if not(tag == 'NNP' or tag == 'NNPS'):\n",
    "                palavra = palavra.lower()\n",
    "            pares.append((palavra, tag))\n",
    "    return pares\n",
    "\n",
    "def construir_dataframe(sentencas: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cria um DataFrame 'longo' com colunas:\n",
    "    sentenca (ID), palavra, tag e posicao_na_sentenca.\n",
    "    \"\"\"\n",
    "    dados = []\n",
    "    for sent_id, sentenca in enumerate(sentencas):\n",
    "        palavras_tags = processar_sentenca(sentenca)\n",
    "        for posicao, (palavra, tag) in enumerate(palavras_tags):\n",
    "            dados.append({\n",
    "                \"sentenca\": sent_id + 1,\n",
    "                \"palavra\": palavra,\n",
    "                \"tag\": tag,\n",
    "                \"posicao_na_sentenca\": posicao\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenca</th>\n",
       "      <th>palavra</th>\n",
       "      <th>tag</th>\n",
       "      <th>posicao_na_sentenca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>years</td>\n",
       "      <td>NNS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentenca palavra  tag  posicao_na_sentenca\n",
       "0         1  Pierre  NNP                    0\n",
       "1         1  Vinken  NNP                    1\n",
       "2         1       ,    ,                    2\n",
       "3         1      61   CD                    3\n",
       "4         1   years  NNS                    4"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando e processando os datasets\n",
    "texto_raw_train = carregar_corpus(train_file)\n",
    "texto_raw_dev = carregar_corpus(dev_file)\n",
    "texto_raw_teste = carregar_corpus(test_file)\n",
    "sentencas_train = dividir_em_sentencas(texto_raw_train + texto_raw_dev + texto_raw_teste)\n",
    "df_treino = construir_dataframe(sentencas_train)\n",
    "df_treino.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Primeiras linhas\n",
    "df_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1173766, 4)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1173766 entries, 0 to 1173765\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   sentenca             1173766 non-null  int64 \n",
      " 1   palavra              1173766 non-null  object\n",
      " 2   tag                  1173766 non-null  object\n",
      " 3   posicao_na_sentenca  1173766 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 35.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_treino.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulário e lista de tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(df_treino[\"tag\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PDT',\n",
       " '#',\n",
       " 'NN',\n",
       " 'WDT',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " '.',\n",
       " 'CD',\n",
       " 'MD',\n",
       " '``',\n",
       " 'LS',\n",
       " 'CC',\n",
       " 'TO',\n",
       " '$',\n",
       " 'JJ',\n",
       " 'VBD',\n",
       " 'PRP$',\n",
       " \"''\",\n",
       " 'PRP',\n",
       " 'RBS',\n",
       " 'SYM',\n",
       " 'VBZ',\n",
       " 'WP$',\n",
       " 'UH',\n",
       " 'POS',\n",
       " 'RB',\n",
       " ':',\n",
       " '-LRB-',\n",
       " 'VB',\n",
       " 'EX',\n",
       " 'DT',\n",
       " '-RRB-',\n",
       " 'VBP',\n",
       " 'WP',\n",
       " 'NNS',\n",
       " 'NNPS',\n",
       " 'RP',\n",
       " 'FW',\n",
       " 'NNP',\n",
       " 'RBR',\n",
       " 'VBN',\n",
       " 'WRB',\n",
       " 'VBG',\n",
       " ',',\n",
       " 'IN']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = list(set(df_treino[\"palavra\"].values))\n",
    "palavras.append(\"<PAD>\") # Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pursue',\n",
       " 'crab',\n",
       " '830.5',\n",
       " 'Pasquale',\n",
       " '99.93',\n",
       " 'farm-machine',\n",
       " 'factored',\n",
       " 'Bookman',\n",
       " 'diGenova',\n",
       " 'Dedham',\n",
       " '64.1',\n",
       " 'attorneys',\n",
       " 'Robinson-Humphrey',\n",
       " 'land-rich',\n",
       " 'inflation-adjusted',\n",
       " 'cuisine',\n",
       " 'pilloried',\n",
       " 'hydroelectric',\n",
       " 'couplets',\n",
       " 'Chateauvallon',\n",
       " 'KPMG',\n",
       " 'inter-office',\n",
       " 'Medicis',\n",
       " 'Hinzack',\n",
       " 'Hilton',\n",
       " 'geometric',\n",
       " 'horse-breeding',\n",
       " 'signed',\n",
       " 'visitors',\n",
       " 'cart',\n",
       " 'Levinson',\n",
       " '20th-century',\n",
       " 'sooner',\n",
       " 'fertilization',\n",
       " 'restroom',\n",
       " 'toned',\n",
       " 'furloughs',\n",
       " 'Lerach',\n",
       " 'intensified',\n",
       " 'Jersey',\n",
       " 'Bekaa',\n",
       " 'capital-markets',\n",
       " 'Shaffer',\n",
       " 'marble-encased',\n",
       " 'spared',\n",
       " 'sino-u.s.',\n",
       " 'Dallas-Barcelona',\n",
       " 'oil-rig',\n",
       " 'cathode-ray',\n",
       " 'Tashkent',\n",
       " 'Elco',\n",
       " 'near-panic',\n",
       " '1.35',\n",
       " 'transforming',\n",
       " 'Kuse',\n",
       " 'devoured',\n",
       " 'Batangas',\n",
       " 'top-performing',\n",
       " 'jamaican',\n",
       " '230,000',\n",
       " 'noncommercial',\n",
       " 'detroit-based',\n",
       " 'purple',\n",
       " 'hens',\n",
       " 'meat-processing',\n",
       " 'wistful',\n",
       " '820.4',\n",
       " 'wrap',\n",
       " 'handling',\n",
       " 'Pincus',\n",
       " 'offhandedly',\n",
       " '17.50',\n",
       " '130.13',\n",
       " 'yield',\n",
       " 'generate',\n",
       " 'Telerate',\n",
       " 'Lai',\n",
       " 'flush',\n",
       " '516',\n",
       " 'tenor',\n",
       " 'parody',\n",
       " 'Professor',\n",
       " 'point-of-sale',\n",
       " 'building-society',\n",
       " 'uranium-mining',\n",
       " 'slaughtered',\n",
       " 'in-law',\n",
       " 'chants',\n",
       " 'deflationary',\n",
       " 'flagging',\n",
       " 'journey',\n",
       " '549.9',\n",
       " 'new-issue',\n",
       " 'Smolensk',\n",
       " 'Novametrix',\n",
       " 'Mikulski',\n",
       " 'portable',\n",
       " 'largest',\n",
       " 'jeweler',\n",
       " 'roustabout',\n",
       " 'Crawford',\n",
       " 'yellows',\n",
       " 'Chemfix',\n",
       " 'Saville',\n",
       " 'majors',\n",
       " 'bestowed',\n",
       " 'radios',\n",
       " 'disappointingly',\n",
       " 'nationalized',\n",
       " 'Skase',\n",
       " '99.821',\n",
       " 'scoop',\n",
       " 'vetoing',\n",
       " 'genre',\n",
       " 'Aguirre-Sacasa',\n",
       " '990,000',\n",
       " 'Walkin',\n",
       " 'lighten',\n",
       " 'MK-Ferguson',\n",
       " 'thwart',\n",
       " 'disapproval',\n",
       " 'storability',\n",
       " 'strikeout',\n",
       " 'fundamentalists',\n",
       " '9.81',\n",
       " 'scrambling',\n",
       " 'resist',\n",
       " 'balconies',\n",
       " '1973-75',\n",
       " '247.6',\n",
       " '50-point',\n",
       " 'behemoth',\n",
       " 'Wight',\n",
       " '79.3',\n",
       " 'bmp-1',\n",
       " 'Veronis',\n",
       " 'memories',\n",
       " 'beeswax',\n",
       " '67.75',\n",
       " 'general-purpose',\n",
       " 'Fernando',\n",
       " 'insurance-claims',\n",
       " 'unexpected',\n",
       " 'gas-gathering',\n",
       " 'oversee',\n",
       " 'epiphany',\n",
       " 'MC',\n",
       " '437.5',\n",
       " 'change',\n",
       " 'Alstyne',\n",
       " 'nonunion',\n",
       " 'aggravating',\n",
       " 'ho-hum',\n",
       " '171',\n",
       " 'Chardon',\n",
       " 'dickered',\n",
       " 'discredit',\n",
       " 'howl',\n",
       " 'expansive',\n",
       " '522.3',\n",
       " 'Myron',\n",
       " 'Collor',\n",
       " 'certificate-of-need',\n",
       " 'graveyard',\n",
       " 'mixes',\n",
       " 'burnout',\n",
       " 'applauding',\n",
       " '450',\n",
       " '12:48',\n",
       " 'Aichi',\n",
       " 'develop',\n",
       " 'company-operated',\n",
       " 'sensitivities',\n",
       " 'custom',\n",
       " 'advise',\n",
       " 'food',\n",
       " 'Sharpshooter',\n",
       " 'debt-equity',\n",
       " 'transvaal',\n",
       " 'Vista',\n",
       " 'fouled',\n",
       " '20-stock',\n",
       " '283.7',\n",
       " 'Eduard',\n",
       " 'well-defined',\n",
       " 'ascending',\n",
       " 'bone',\n",
       " 'pluralism',\n",
       " 'memorial',\n",
       " 'MacroChem',\n",
       " 'emerges',\n",
       " 'constituent',\n",
       " 'Picture',\n",
       " 'french-made',\n",
       " 'subtraction',\n",
       " '315.12',\n",
       " 'unaffected',\n",
       " 'widowed',\n",
       " 'visit',\n",
       " 'exported',\n",
       " 'personal',\n",
       " 'populous',\n",
       " 'mapping',\n",
       " 'direct',\n",
       " 'relaunch',\n",
       " 'sank',\n",
       " 'heels',\n",
       " 'MCI',\n",
       " 'Longwood',\n",
       " 'Moscow',\n",
       " 'Ilford',\n",
       " 'apology',\n",
       " 'artillery',\n",
       " 'Brozman',\n",
       " 'Industrial',\n",
       " 'cement-truck',\n",
       " 'Harkins',\n",
       " 'gamblers',\n",
       " 'Allentown',\n",
       " '25.25',\n",
       " 'castings',\n",
       " 'underwriter',\n",
       " 'begot',\n",
       " 'wring',\n",
       " 'farm',\n",
       " 'comply',\n",
       " 'Recovery',\n",
       " 'Hampshire',\n",
       " 'service-industry',\n",
       " 'overshadowing',\n",
       " '6.81',\n",
       " 'hotel\\\\/casino',\n",
       " 'better-safe-than',\n",
       " 'embodies',\n",
       " 'Korff',\n",
       " 'cod-liver',\n",
       " 'racket',\n",
       " 'punts',\n",
       " 'happier',\n",
       " '16',\n",
       " 'Cosgrove-Meurer',\n",
       " 'N.',\n",
       " 'Disc',\n",
       " 'gore',\n",
       " 'revisions',\n",
       " 'disseminated',\n",
       " 'entity',\n",
       " 'Derel',\n",
       " '11:59',\n",
       " 'lubricants',\n",
       " 'flinch',\n",
       " '45.50',\n",
       " 'namibian',\n",
       " '54.58',\n",
       " '448',\n",
       " 'Recruit',\n",
       " 'capital-gains',\n",
       " 'snagged',\n",
       " 'pornographic',\n",
       " 'debt-rating',\n",
       " 'PegaSys',\n",
       " 'MERRILL',\n",
       " 'eight-person',\n",
       " 'soon',\n",
       " 'outlining',\n",
       " 'Eminase',\n",
       " 'updates',\n",
       " 'Tonawanda',\n",
       " 'dissolved',\n",
       " 'stacks',\n",
       " '134.9',\n",
       " 'permanent',\n",
       " '743.7',\n",
       " \"d'Exploitation\",\n",
       " 'croak',\n",
       " 'Schloss',\n",
       " 'true',\n",
       " '30.2',\n",
       " 'harangues',\n",
       " 'painters',\n",
       " 'Hang',\n",
       " 'irrepressible',\n",
       " '22.9',\n",
       " 'earnest',\n",
       " 'Redfield',\n",
       " 'newspaper',\n",
       " 'pains',\n",
       " 'probation',\n",
       " 'fairfax',\n",
       " 'States',\n",
       " 'Becca',\n",
       " 'fractioning',\n",
       " 'condemns',\n",
       " 'burglarized',\n",
       " 'fortuitous',\n",
       " 'alerts',\n",
       " 'Leach',\n",
       " 'discarded',\n",
       " 'free-enterprise',\n",
       " '1937',\n",
       " 'Jelenic',\n",
       " 'Seib',\n",
       " 'Deputy',\n",
       " 'forgiving',\n",
       " 'Papers',\n",
       " 'M.B.A.',\n",
       " '5.163',\n",
       " 'detractors',\n",
       " 'chess',\n",
       " 'garments',\n",
       " 'Soap',\n",
       " 'deterrence',\n",
       " 'minicomputers',\n",
       " '622',\n",
       " 'prostitution',\n",
       " 'twice',\n",
       " 'schmumpered',\n",
       " 'Emirates',\n",
       " 'rhymes',\n",
       " 'adversarial',\n",
       " 'clerk-turned',\n",
       " 'goods',\n",
       " 'disturbs',\n",
       " '52.1',\n",
       " 'luxury-suite',\n",
       " '730,070',\n",
       " 'demolish',\n",
       " 'negotiation',\n",
       " 'Petrovich',\n",
       " 'manuevering',\n",
       " 'credit-rating',\n",
       " 'Lily',\n",
       " 'radiant',\n",
       " 'superceded',\n",
       " 'Stedt',\n",
       " 'extricate',\n",
       " 'about',\n",
       " 'occupying',\n",
       " '241.7',\n",
       " 'differs',\n",
       " 'tasting',\n",
       " 'Sunset',\n",
       " 'Managers',\n",
       " 'Bolduc',\n",
       " 'classless',\n",
       " 'weakness',\n",
       " 'disengage',\n",
       " 'biologist',\n",
       " 'labs',\n",
       " 'peering',\n",
       " '2681.76',\n",
       " 'cut-rate',\n",
       " 'Sewing',\n",
       " 'faculty',\n",
       " 'tangle',\n",
       " 'rollover',\n",
       " 'arrive',\n",
       " 'sixties',\n",
       " 'affirming',\n",
       " 'estranged',\n",
       " 'horticulturally',\n",
       " '0.31',\n",
       " 'pysllium',\n",
       " 'weighty',\n",
       " 'intelligent',\n",
       " 'buoyancy',\n",
       " 'heckled',\n",
       " 'Reedy',\n",
       " 'courses',\n",
       " 'pampers',\n",
       " 'Pilevsky',\n",
       " 'defraud',\n",
       " 'Nishimura',\n",
       " 'ancillary',\n",
       " 'burdens',\n",
       " 'oasis',\n",
       " 'good-til-canceled',\n",
       " 'Greene',\n",
       " 'counters',\n",
       " 'Verdi',\n",
       " 'example',\n",
       " '212.5',\n",
       " 'herself',\n",
       " 'tenaciously',\n",
       " 'struggled',\n",
       " 'Balzac',\n",
       " 'Fax',\n",
       " '813',\n",
       " 'globe',\n",
       " 'popularized',\n",
       " 'intertwined',\n",
       " 'Shapiro',\n",
       " 'Zombie',\n",
       " 'press',\n",
       " 'run-ins',\n",
       " 'disbanded',\n",
       " 'hand-lotion',\n",
       " '174',\n",
       " 'intertwining',\n",
       " 'quota-trained',\n",
       " 'unamused',\n",
       " 'waive',\n",
       " 'white-washed',\n",
       " 'course-correction',\n",
       " 'traveled',\n",
       " 'Placements',\n",
       " 'Sheremetyevo',\n",
       " 'Cadillac',\n",
       " 'deletions',\n",
       " 'bedroom',\n",
       " 'triangles',\n",
       " 'wagoneer',\n",
       " 'dog-meat',\n",
       " 'intergenerational',\n",
       " 'Somalis',\n",
       " 'Kakumaru',\n",
       " 'spinoffs',\n",
       " 'Crane',\n",
       " 'Fanuc',\n",
       " 'chicken-mutilating',\n",
       " 'colleges',\n",
       " 'Testa',\n",
       " 'Payroll',\n",
       " 'heady',\n",
       " 'hamburger',\n",
       " 'Honeybee',\n",
       " 'indonesian',\n",
       " 'tidy',\n",
       " 'Trish',\n",
       " '99.7',\n",
       " 'Major',\n",
       " 'Toys',\n",
       " 'extramarital',\n",
       " 'administered',\n",
       " 'instinctively',\n",
       " 'undeniably',\n",
       " 'Brothers',\n",
       " '1.4',\n",
       " 'No',\n",
       " 'electrical',\n",
       " 'Amarillo',\n",
       " 'Caucus',\n",
       " 'Comfort',\n",
       " 'cost-of-living',\n",
       " 'multimillion-dollar',\n",
       " 'over',\n",
       " 'Nahas',\n",
       " '8.325',\n",
       " 'specialties',\n",
       " 'banquet-hall',\n",
       " '74.8',\n",
       " 'Denrees',\n",
       " 'reflexively',\n",
       " 'vigor',\n",
       " '4.25',\n",
       " 'tensions',\n",
       " 'divesting',\n",
       " 'spruce',\n",
       " '16.25',\n",
       " 'delivery',\n",
       " '149.3',\n",
       " 'Reproductive',\n",
       " '18.75',\n",
       " '4th',\n",
       " 'couriers',\n",
       " 'Scania',\n",
       " 'archival',\n",
       " 'richmond-area',\n",
       " 'restructurings',\n",
       " 'sell-order',\n",
       " 'sunshine',\n",
       " 'soups',\n",
       " 'mailing',\n",
       " 'kellogg',\n",
       " 'death-backed',\n",
       " 'midnight',\n",
       " 'Veterans',\n",
       " 'advising',\n",
       " '366.85',\n",
       " 'Vahid',\n",
       " 'ubiquitous',\n",
       " 'earth',\n",
       " 'Lyphomed',\n",
       " 'wondered',\n",
       " '65.2',\n",
       " 'canyons',\n",
       " 'peddle',\n",
       " 'elementary',\n",
       " 'conservative-communist',\n",
       " 'decelerated',\n",
       " 'Carney',\n",
       " 'Citibank',\n",
       " 'ineffectual',\n",
       " 'hardball',\n",
       " 'Electrolux',\n",
       " 'unsuccessfully',\n",
       " '7.1',\n",
       " 'waiver',\n",
       " 'Stoltzman',\n",
       " 'spokespersons',\n",
       " 'longshoreman',\n",
       " 'Pine',\n",
       " 'Wilber',\n",
       " 'Lincoln-Mercury-Merkur',\n",
       " 'listings',\n",
       " 'snapshots',\n",
       " 'Tully',\n",
       " 'short-changing',\n",
       " 'presses',\n",
       " 'interleukin-2',\n",
       " 'banker',\n",
       " 'shipments',\n",
       " 'Hammerton',\n",
       " 'ratified',\n",
       " 'County',\n",
       " '36',\n",
       " 'tax',\n",
       " 'Right',\n",
       " 'conceal',\n",
       " 'incongruities',\n",
       " 'high-production',\n",
       " '1263.51',\n",
       " 'abolishing',\n",
       " 'implying',\n",
       " 'readmit',\n",
       " 'a',\n",
       " 'chic',\n",
       " 'status-conscious',\n",
       " '44.50',\n",
       " 'Amityvilles',\n",
       " 'reunification',\n",
       " 'Brophy',\n",
       " 'money',\n",
       " 'Clarke',\n",
       " 'sabers',\n",
       " 'surfaced',\n",
       " 'scimed',\n",
       " 'Mortimer',\n",
       " 'Deloitte',\n",
       " 'Hollingsworth',\n",
       " '335',\n",
       " 'AK-47',\n",
       " 'Cosmetics',\n",
       " 'exclusivity',\n",
       " 'Enfield',\n",
       " 'Halis',\n",
       " 'mother-in-law',\n",
       " 'Declan',\n",
       " 'Suez',\n",
       " '2689.14',\n",
       " 'Sausalito',\n",
       " 'lawful',\n",
       " 'Messinger',\n",
       " 'Gabele',\n",
       " 'pittsburgh-based',\n",
       " 'acclaimed',\n",
       " '354,000',\n",
       " 'deviation',\n",
       " 'arena',\n",
       " 'cracker',\n",
       " 'unify',\n",
       " 'photofinishing',\n",
       " '99.14',\n",
       " 'impressed',\n",
       " 'debtors',\n",
       " 'treasures',\n",
       " 'psychological',\n",
       " 'Halloween',\n",
       " '11,762',\n",
       " 'Diabetes',\n",
       " 'hurricane',\n",
       " 'lender',\n",
       " '20-a-share',\n",
       " '8300',\n",
       " 'auto-dealer',\n",
       " 'bomber',\n",
       " 'conscripts',\n",
       " 'reckoned',\n",
       " 'curious',\n",
       " 'address',\n",
       " 'air-waybill',\n",
       " 'throw',\n",
       " 'collegiate',\n",
       " 'McMillin',\n",
       " '790.2',\n",
       " 'bearable',\n",
       " 'excavated',\n",
       " '757',\n",
       " 'principle',\n",
       " 'corporate-owned',\n",
       " 'mist',\n",
       " 'Assemblyman',\n",
       " '7.05',\n",
       " 'Wine',\n",
       " 'resists',\n",
       " 'jumpy',\n",
       " 'packaging',\n",
       " 'droopy-eyed',\n",
       " 'reimburses',\n",
       " 'Cologne',\n",
       " 'serious',\n",
       " 'discloses',\n",
       " '195.4',\n",
       " 'Boon',\n",
       " 'twisted',\n",
       " 'lumping',\n",
       " 'haul',\n",
       " 'transmission',\n",
       " 'gracious',\n",
       " '40.1',\n",
       " 'Carew',\n",
       " '46.8',\n",
       " 'assassinated',\n",
       " 'feckless',\n",
       " 'pays',\n",
       " '753',\n",
       " 'Challenger',\n",
       " '0.24',\n",
       " '44,400',\n",
       " 'Telzrow',\n",
       " 'prejudices',\n",
       " '18,136',\n",
       " 'researcher',\n",
       " 'bachelor',\n",
       " 'Bowers',\n",
       " 'advanced',\n",
       " '341.16',\n",
       " '44-year-old',\n",
       " 'eventually',\n",
       " 'trust',\n",
       " 'Mich.',\n",
       " 'Nyiregyhaza',\n",
       " 'RMS',\n",
       " 'sexy',\n",
       " '14.28',\n",
       " 'sprinkles',\n",
       " 'Sugar',\n",
       " 'eight-count',\n",
       " 'fending',\n",
       " 'propellant',\n",
       " 'exacerbates',\n",
       " 'Barnabas',\n",
       " 'alienating',\n",
       " '2,600',\n",
       " 'Scurlock',\n",
       " 'inwardly',\n",
       " 'Mines',\n",
       " 'exits',\n",
       " 'Elisabeth',\n",
       " 'segregated',\n",
       " 'epic',\n",
       " 'fiat',\n",
       " 'horsepower',\n",
       " 'anti-science',\n",
       " 'Cawthorn',\n",
       " 'principles',\n",
       " 'Puente',\n",
       " 'Dead',\n",
       " 'flavor',\n",
       " 'Inter',\n",
       " 'workforce',\n",
       " 'Sarasota',\n",
       " 'E.R.',\n",
       " 'absorbed',\n",
       " 'emigration',\n",
       " 'Convex',\n",
       " 'characterizes',\n",
       " 'volcano',\n",
       " 'Crash',\n",
       " 'high-yield',\n",
       " 'invent',\n",
       " 'dispense',\n",
       " 'straining',\n",
       " 'vacating',\n",
       " 'builds',\n",
       " 'Sigoloff',\n",
       " 'Harlan',\n",
       " 'townhouses',\n",
       " 'skill',\n",
       " 'flotations',\n",
       " 'Triborough',\n",
       " 'Fredric',\n",
       " 'Buksbaum',\n",
       " 'berated',\n",
       " 'discover',\n",
       " 'Roebuck',\n",
       " 'sits',\n",
       " '1,838,200',\n",
       " 'Southport',\n",
       " 'feline',\n",
       " 'publication',\n",
       " 'embassy',\n",
       " 'shakespeare',\n",
       " 'payables',\n",
       " 'symbolism',\n",
       " 'Electrical',\n",
       " 'capitalist',\n",
       " 'forgot',\n",
       " 'american-made',\n",
       " 'higher-quality',\n",
       " 'Teresa',\n",
       " 'arbitrage',\n",
       " 'water-submersion',\n",
       " 'Oil',\n",
       " '33,000',\n",
       " 'selections',\n",
       " 'ancient',\n",
       " 'applaud',\n",
       " 'faking',\n",
       " 'derail',\n",
       " 'hay',\n",
       " 'accompanied',\n",
       " 'krater',\n",
       " 'guesswork',\n",
       " 'doubly',\n",
       " 'wrested',\n",
       " 'unsubsidized',\n",
       " 'Sabina',\n",
       " 'streets',\n",
       " 'Omega',\n",
       " 'Valu',\n",
       " 'socialism',\n",
       " 'Wah',\n",
       " 'Proleukin',\n",
       " 'uttering',\n",
       " '1986',\n",
       " 'racism',\n",
       " 'juries',\n",
       " 'memorabilia',\n",
       " 'Adamski',\n",
       " 'yearbook',\n",
       " 'eyeballing',\n",
       " 'moonie',\n",
       " 'newsweekly',\n",
       " 'Christ',\n",
       " 'withdrawal',\n",
       " 'randomly',\n",
       " 'XR4Ti',\n",
       " 'visited',\n",
       " 'four-stroke',\n",
       " 'blotting',\n",
       " 'candles',\n",
       " 'billionnaire',\n",
       " 'retail',\n",
       " 'Koerner',\n",
       " 'profligate',\n",
       " 'Lindner',\n",
       " 'Testing',\n",
       " 'cancer-suppressing',\n",
       " 'Ticor',\n",
       " 'hazelnut',\n",
       " '51-cash',\n",
       " 'coniston',\n",
       " 'ubiquity',\n",
       " 'jackals',\n",
       " 'Asset',\n",
       " 'lingering',\n",
       " 'Rash',\n",
       " 'rescind',\n",
       " 'complicity',\n",
       " '34-foot-tall',\n",
       " 'accountants',\n",
       " 'prowess',\n",
       " 'mythic',\n",
       " 'shortages',\n",
       " 'lilting',\n",
       " 'commented',\n",
       " '324',\n",
       " 'Stouffer',\n",
       " 'distributors',\n",
       " 'intermixed',\n",
       " 'scenes',\n",
       " 'cement-mixing',\n",
       " 'personal-computer',\n",
       " 'cheese',\n",
       " 'temporarily',\n",
       " 'Willie',\n",
       " 'periodically',\n",
       " '159',\n",
       " 'Higher',\n",
       " 'Mogadishu',\n",
       " 'Plymouth',\n",
       " 'Homeless',\n",
       " 'Betty',\n",
       " 'Hibler',\n",
       " '411',\n",
       " '10-month',\n",
       " 'Facility',\n",
       " 'extraordinary',\n",
       " 'posting',\n",
       " 'unveil',\n",
       " 'divers',\n",
       " 'Birney',\n",
       " 'zero-inflation',\n",
       " 'roadbed',\n",
       " 'indian',\n",
       " 'Turtles',\n",
       " 'investigator',\n",
       " 'Ritterman',\n",
       " 'small-fry',\n",
       " '2791.41',\n",
       " 'dollar',\n",
       " 'arsenals',\n",
       " 'two-time',\n",
       " 'Housing',\n",
       " 'fanny',\n",
       " 'interior',\n",
       " 'Pilson',\n",
       " 'maxim',\n",
       " 'Fox-Meyer',\n",
       " 'windows',\n",
       " 'milwaukee-based',\n",
       " 'Bacarella',\n",
       " '357.4',\n",
       " 'venerable',\n",
       " 'robbing',\n",
       " '12,252',\n",
       " '101,250',\n",
       " '85.8',\n",
       " 'oppression',\n",
       " 'Mesa',\n",
       " 'biographer',\n",
       " '7',\n",
       " 'delicately',\n",
       " 'jugglers',\n",
       " 'planet',\n",
       " 'Tracers',\n",
       " '128.19',\n",
       " 'verifiable',\n",
       " 'sciences',\n",
       " 'vicars',\n",
       " 'spearheading',\n",
       " 'black-draped',\n",
       " 'Names',\n",
       " 'implicate',\n",
       " 'stint',\n",
       " 'slipshod',\n",
       " 'Kirghiz',\n",
       " 'Vandenberg',\n",
       " 'Soichiro',\n",
       " 'tick',\n",
       " 'territory',\n",
       " 'Lep',\n",
       " 'Naomi',\n",
       " 'turned',\n",
       " 'paraphernalia',\n",
       " 'Itel',\n",
       " 'city-wide',\n",
       " 'law-governed',\n",
       " 'begins',\n",
       " 'over-optimistic',\n",
       " 'staff',\n",
       " 'Sr.',\n",
       " 'pre-strike',\n",
       " 'capital-punishment',\n",
       " 'Gilgore',\n",
       " 'Hotels',\n",
       " 'herring',\n",
       " 'venal',\n",
       " 'constructively',\n",
       " 'hardware',\n",
       " 'Lyon',\n",
       " 'knows',\n",
       " 'cyclical',\n",
       " 'MPD',\n",
       " 'classical-music',\n",
       " '2,888,000',\n",
       " 'Langendorf',\n",
       " 'yankee',\n",
       " 'EXXON',\n",
       " 'environment',\n",
       " 'salad',\n",
       " 'rewrapped',\n",
       " 'unrealized',\n",
       " 'Greenwood',\n",
       " 'Mountains',\n",
       " 'analogous',\n",
       " 'Open',\n",
       " 'hunting',\n",
       " 'Eurodollar',\n",
       " 'whiner',\n",
       " 'wholly',\n",
       " '7.32',\n",
       " 'skillful',\n",
       " '219.19',\n",
       " 'chasing',\n",
       " 'reiterating',\n",
       " 'disinterested',\n",
       " 'Parts',\n",
       " 'indicators',\n",
       " 'rematch',\n",
       " 'Phelan',\n",
       " '792',\n",
       " 'R.I.',\n",
       " 'shells',\n",
       " '5.58',\n",
       " 'dissuade',\n",
       " '500-store',\n",
       " 'Rochester',\n",
       " 'underperformed',\n",
       " 'gratuities',\n",
       " 'executed',\n",
       " 'abandons',\n",
       " '861',\n",
       " 'roars',\n",
       " 'Connoisseur',\n",
       " 'servers',\n",
       " 'platter',\n",
       " 'costing',\n",
       " 'Refinery',\n",
       " '160,000',\n",
       " 'near-record',\n",
       " 'Ferembal',\n",
       " 'spilling',\n",
       " 'Playhouse',\n",
       " 'calculations',\n",
       " 'disdaining',\n",
       " 'petitioned',\n",
       " 'desultory',\n",
       " 'shambles',\n",
       " 'supply-sider',\n",
       " 'purports',\n",
       " 'manipulating',\n",
       " 'Refcorp',\n",
       " 'Record',\n",
       " 'rigorous',\n",
       " 'slats',\n",
       " 'sacking',\n",
       " 'discrete',\n",
       " 'finals',\n",
       " 'skim',\n",
       " 'cripples',\n",
       " 'short-selling',\n",
       " 'fledgling',\n",
       " 'Warner',\n",
       " 'paring',\n",
       " 'Packwood',\n",
       " 'Bebear',\n",
       " '23.31',\n",
       " 'Alurralde',\n",
       " 'trio',\n",
       " 'exploiting',\n",
       " 'P.J.',\n",
       " 'movieland',\n",
       " 'regulation',\n",
       " 'outlay',\n",
       " 'fidgeting',\n",
       " 'friers',\n",
       " 'Sajak',\n",
       " 'cheetah',\n",
       " 'smaller-size',\n",
       " '1989-90',\n",
       " 'server',\n",
       " '6.5',\n",
       " 'testers',\n",
       " 'answering',\n",
       " 'apparently',\n",
       " 'autonomy',\n",
       " 'rook',\n",
       " 'consumption',\n",
       " 'Ski',\n",
       " 'well-intended',\n",
       " 'base-price',\n",
       " 'u.s.-style',\n",
       " 'biomedical-products',\n",
       " 'age-specific',\n",
       " 'hemoglobin',\n",
       " 'patrons',\n",
       " 'comparatively',\n",
       " 'syndicates',\n",
       " 'L.J.',\n",
       " 'parted',\n",
       " 'Bucaramanga',\n",
       " 'Tripoli',\n",
       " 'rescissions',\n",
       " 'pilot-seniority',\n",
       " 'DEPOSIT',\n",
       " 'pertinent',\n",
       " 'endlessly',\n",
       " 'Multilateral',\n",
       " '3636.06',\n",
       " 'powered',\n",
       " 'Pale',\n",
       " 'Pool',\n",
       " 'ba-3',\n",
       " 'aspirations',\n",
       " 'MeraBank',\n",
       " 'sink',\n",
       " 'uniquely',\n",
       " 'banning',\n",
       " 'purely',\n",
       " '361,000',\n",
       " 'psychoanalyst',\n",
       " 'sifted',\n",
       " 'steadied',\n",
       " 'match',\n",
       " 'gratuity',\n",
       " '211.96',\n",
       " 'quick-service',\n",
       " 'coffee-shop',\n",
       " ...]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar em sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LerSentencas(object): \n",
    "    \n",
    "    def __init__(self, dados):\n",
    "        self.dados = dados\n",
    "        self.vazio = False\n",
    "        agg_func = lambda s: [(w, p) for w, p in zip(s[\"palavra\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.agrupado = self.dados.groupby(\"sentenca\").apply(agg_func)\n",
    "        self.sentencas = [s for s in self.agrupado]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencas_treino = LerSentencas(df_treino).sentencas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencas_treino[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo palavras e tags em números\n",
    "word2id = {w: i for i, w in enumerate(palavras)}\n",
    "tag2id = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pursue': 0,\n",
       " 'crab': 1,\n",
       " '830.5': 2,\n",
       " 'Pasquale': 3,\n",
       " '99.93': 4,\n",
       " 'farm-machine': 5,\n",
       " 'factored': 6,\n",
       " 'Bookman': 7,\n",
       " 'diGenova': 8,\n",
       " 'Dedham': 9,\n",
       " '64.1': 10,\n",
       " 'attorneys': 11,\n",
       " 'Robinson-Humphrey': 12,\n",
       " 'land-rich': 13,\n",
       " 'inflation-adjusted': 14,\n",
       " 'cuisine': 15,\n",
       " 'pilloried': 16,\n",
       " 'hydroelectric': 17,\n",
       " 'couplets': 18,\n",
       " 'Chateauvallon': 19,\n",
       " 'KPMG': 20,\n",
       " 'inter-office': 21,\n",
       " 'Medicis': 22,\n",
       " 'Hinzack': 23,\n",
       " 'Hilton': 24,\n",
       " 'geometric': 25,\n",
       " 'horse-breeding': 26,\n",
       " 'signed': 27,\n",
       " 'visitors': 28,\n",
       " 'cart': 29,\n",
       " 'Levinson': 30,\n",
       " '20th-century': 31,\n",
       " 'sooner': 32,\n",
       " 'fertilization': 33,\n",
       " 'restroom': 34,\n",
       " 'toned': 35,\n",
       " 'furloughs': 36,\n",
       " 'Lerach': 37,\n",
       " 'intensified': 38,\n",
       " 'Jersey': 39,\n",
       " 'Bekaa': 40,\n",
       " 'capital-markets': 41,\n",
       " 'Shaffer': 42,\n",
       " 'marble-encased': 43,\n",
       " 'spared': 44,\n",
       " 'sino-u.s.': 45,\n",
       " 'Dallas-Barcelona': 46,\n",
       " 'oil-rig': 47,\n",
       " 'cathode-ray': 48,\n",
       " 'Tashkent': 49,\n",
       " 'Elco': 50,\n",
       " 'near-panic': 51,\n",
       " '1.35': 52,\n",
       " 'transforming': 53,\n",
       " 'Kuse': 54,\n",
       " 'devoured': 55,\n",
       " 'Batangas': 56,\n",
       " 'top-performing': 57,\n",
       " 'jamaican': 58,\n",
       " '230,000': 59,\n",
       " 'noncommercial': 60,\n",
       " 'detroit-based': 61,\n",
       " 'purple': 62,\n",
       " 'hens': 63,\n",
       " 'meat-processing': 64,\n",
       " 'wistful': 65,\n",
       " '820.4': 66,\n",
       " 'wrap': 67,\n",
       " 'handling': 68,\n",
       " 'Pincus': 69,\n",
       " 'offhandedly': 70,\n",
       " '17.50': 71,\n",
       " '130.13': 72,\n",
       " 'yield': 73,\n",
       " 'generate': 74,\n",
       " 'Telerate': 75,\n",
       " 'Lai': 76,\n",
       " 'flush': 77,\n",
       " '516': 78,\n",
       " 'tenor': 79,\n",
       " 'parody': 80,\n",
       " 'Professor': 81,\n",
       " 'point-of-sale': 82,\n",
       " 'building-society': 83,\n",
       " 'uranium-mining': 84,\n",
       " 'slaughtered': 85,\n",
       " 'in-law': 86,\n",
       " 'chants': 87,\n",
       " 'deflationary': 88,\n",
       " 'flagging': 89,\n",
       " 'journey': 90,\n",
       " '549.9': 91,\n",
       " 'new-issue': 92,\n",
       " 'Smolensk': 93,\n",
       " 'Novametrix': 94,\n",
       " 'Mikulski': 95,\n",
       " 'portable': 96,\n",
       " 'largest': 97,\n",
       " 'jeweler': 98,\n",
       " 'roustabout': 99,\n",
       " 'Crawford': 100,\n",
       " 'yellows': 101,\n",
       " 'Chemfix': 102,\n",
       " 'Saville': 103,\n",
       " 'majors': 104,\n",
       " 'bestowed': 105,\n",
       " 'radios': 106,\n",
       " 'disappointingly': 107,\n",
       " 'nationalized': 108,\n",
       " 'Skase': 109,\n",
       " '99.821': 110,\n",
       " 'scoop': 111,\n",
       " 'vetoing': 112,\n",
       " 'genre': 113,\n",
       " 'Aguirre-Sacasa': 114,\n",
       " '990,000': 115,\n",
       " 'Walkin': 116,\n",
       " 'lighten': 117,\n",
       " 'MK-Ferguson': 118,\n",
       " 'thwart': 119,\n",
       " 'disapproval': 120,\n",
       " 'storability': 121,\n",
       " 'strikeout': 122,\n",
       " 'fundamentalists': 123,\n",
       " '9.81': 124,\n",
       " 'scrambling': 125,\n",
       " 'resist': 126,\n",
       " 'balconies': 127,\n",
       " '1973-75': 128,\n",
       " '247.6': 129,\n",
       " '50-point': 130,\n",
       " 'behemoth': 131,\n",
       " 'Wight': 132,\n",
       " '79.3': 133,\n",
       " 'bmp-1': 134,\n",
       " 'Veronis': 135,\n",
       " 'memories': 136,\n",
       " 'beeswax': 137,\n",
       " '67.75': 138,\n",
       " 'general-purpose': 139,\n",
       " 'Fernando': 140,\n",
       " 'insurance-claims': 141,\n",
       " 'unexpected': 142,\n",
       " 'gas-gathering': 143,\n",
       " 'oversee': 144,\n",
       " 'epiphany': 145,\n",
       " 'MC': 146,\n",
       " '437.5': 147,\n",
       " 'change': 148,\n",
       " 'Alstyne': 149,\n",
       " 'nonunion': 150,\n",
       " 'aggravating': 151,\n",
       " 'ho-hum': 152,\n",
       " '171': 153,\n",
       " 'Chardon': 154,\n",
       " 'dickered': 155,\n",
       " 'discredit': 156,\n",
       " 'howl': 157,\n",
       " 'expansive': 158,\n",
       " '522.3': 159,\n",
       " 'Myron': 160,\n",
       " 'Collor': 161,\n",
       " 'certificate-of-need': 162,\n",
       " 'graveyard': 163,\n",
       " 'mixes': 164,\n",
       " 'burnout': 165,\n",
       " 'applauding': 166,\n",
       " '450': 167,\n",
       " '12:48': 168,\n",
       " 'Aichi': 169,\n",
       " 'develop': 170,\n",
       " 'company-operated': 171,\n",
       " 'sensitivities': 172,\n",
       " 'custom': 173,\n",
       " 'advise': 174,\n",
       " 'food': 175,\n",
       " 'Sharpshooter': 176,\n",
       " 'debt-equity': 177,\n",
       " 'transvaal': 178,\n",
       " 'Vista': 179,\n",
       " 'fouled': 180,\n",
       " '20-stock': 181,\n",
       " '283.7': 182,\n",
       " 'Eduard': 183,\n",
       " 'well-defined': 184,\n",
       " 'ascending': 185,\n",
       " 'bone': 186,\n",
       " 'pluralism': 187,\n",
       " 'memorial': 188,\n",
       " 'MacroChem': 189,\n",
       " 'emerges': 190,\n",
       " 'constituent': 191,\n",
       " 'Picture': 192,\n",
       " 'french-made': 193,\n",
       " 'subtraction': 194,\n",
       " '315.12': 195,\n",
       " 'unaffected': 196,\n",
       " 'widowed': 197,\n",
       " 'visit': 198,\n",
       " 'exported': 199,\n",
       " 'personal': 200,\n",
       " 'populous': 201,\n",
       " 'mapping': 202,\n",
       " 'direct': 203,\n",
       " 'relaunch': 204,\n",
       " 'sank': 205,\n",
       " 'heels': 206,\n",
       " 'MCI': 207,\n",
       " 'Longwood': 208,\n",
       " 'Moscow': 209,\n",
       " 'Ilford': 210,\n",
       " 'apology': 211,\n",
       " 'artillery': 212,\n",
       " 'Brozman': 213,\n",
       " 'Industrial': 214,\n",
       " 'cement-truck': 215,\n",
       " 'Harkins': 216,\n",
       " 'gamblers': 217,\n",
       " 'Allentown': 218,\n",
       " '25.25': 219,\n",
       " 'castings': 220,\n",
       " 'underwriter': 221,\n",
       " 'begot': 222,\n",
       " 'wring': 223,\n",
       " 'farm': 224,\n",
       " 'comply': 225,\n",
       " 'Recovery': 226,\n",
       " 'Hampshire': 227,\n",
       " 'service-industry': 228,\n",
       " 'overshadowing': 229,\n",
       " '6.81': 230,\n",
       " 'hotel\\\\/casino': 231,\n",
       " 'better-safe-than': 232,\n",
       " 'embodies': 233,\n",
       " 'Korff': 234,\n",
       " 'cod-liver': 235,\n",
       " 'racket': 236,\n",
       " 'punts': 237,\n",
       " 'happier': 238,\n",
       " '16': 239,\n",
       " 'Cosgrove-Meurer': 240,\n",
       " 'N.': 241,\n",
       " 'Disc': 242,\n",
       " 'gore': 243,\n",
       " 'revisions': 244,\n",
       " 'disseminated': 245,\n",
       " 'entity': 246,\n",
       " 'Derel': 247,\n",
       " '11:59': 248,\n",
       " 'lubricants': 249,\n",
       " 'flinch': 250,\n",
       " '45.50': 251,\n",
       " 'namibian': 252,\n",
       " '54.58': 253,\n",
       " '448': 254,\n",
       " 'Recruit': 255,\n",
       " 'capital-gains': 256,\n",
       " 'snagged': 257,\n",
       " 'pornographic': 258,\n",
       " 'debt-rating': 259,\n",
       " 'PegaSys': 260,\n",
       " 'MERRILL': 261,\n",
       " 'eight-person': 262,\n",
       " 'soon': 263,\n",
       " 'outlining': 264,\n",
       " 'Eminase': 265,\n",
       " 'updates': 266,\n",
       " 'Tonawanda': 267,\n",
       " 'dissolved': 268,\n",
       " 'stacks': 269,\n",
       " '134.9': 270,\n",
       " 'permanent': 271,\n",
       " '743.7': 272,\n",
       " \"d'Exploitation\": 273,\n",
       " 'croak': 274,\n",
       " 'Schloss': 275,\n",
       " 'true': 276,\n",
       " '30.2': 277,\n",
       " 'harangues': 278,\n",
       " 'painters': 279,\n",
       " 'Hang': 280,\n",
       " 'irrepressible': 281,\n",
       " '22.9': 282,\n",
       " 'earnest': 283,\n",
       " 'Redfield': 284,\n",
       " 'newspaper': 285,\n",
       " 'pains': 286,\n",
       " 'probation': 287,\n",
       " 'fairfax': 288,\n",
       " 'States': 289,\n",
       " 'Becca': 290,\n",
       " 'fractioning': 291,\n",
       " 'condemns': 292,\n",
       " 'burglarized': 293,\n",
       " 'fortuitous': 294,\n",
       " 'alerts': 295,\n",
       " 'Leach': 296,\n",
       " 'discarded': 297,\n",
       " 'free-enterprise': 298,\n",
       " '1937': 299,\n",
       " 'Jelenic': 300,\n",
       " 'Seib': 301,\n",
       " 'Deputy': 302,\n",
       " 'forgiving': 303,\n",
       " 'Papers': 304,\n",
       " 'M.B.A.': 305,\n",
       " '5.163': 306,\n",
       " 'detractors': 307,\n",
       " 'chess': 308,\n",
       " 'garments': 309,\n",
       " 'Soap': 310,\n",
       " 'deterrence': 311,\n",
       " 'minicomputers': 312,\n",
       " '622': 313,\n",
       " 'prostitution': 314,\n",
       " 'twice': 315,\n",
       " 'schmumpered': 316,\n",
       " 'Emirates': 317,\n",
       " 'rhymes': 318,\n",
       " 'adversarial': 319,\n",
       " 'clerk-turned': 320,\n",
       " 'goods': 321,\n",
       " 'disturbs': 322,\n",
       " '52.1': 323,\n",
       " 'luxury-suite': 324,\n",
       " '730,070': 325,\n",
       " 'demolish': 326,\n",
       " 'negotiation': 327,\n",
       " 'Petrovich': 328,\n",
       " 'manuevering': 329,\n",
       " 'credit-rating': 330,\n",
       " 'Lily': 331,\n",
       " 'radiant': 332,\n",
       " 'superceded': 333,\n",
       " 'Stedt': 334,\n",
       " 'extricate': 335,\n",
       " 'about': 336,\n",
       " 'occupying': 337,\n",
       " '241.7': 338,\n",
       " 'differs': 339,\n",
       " 'tasting': 340,\n",
       " 'Sunset': 341,\n",
       " 'Managers': 342,\n",
       " 'Bolduc': 343,\n",
       " 'classless': 344,\n",
       " 'weakness': 345,\n",
       " 'disengage': 346,\n",
       " 'biologist': 347,\n",
       " 'labs': 348,\n",
       " 'peering': 349,\n",
       " '2681.76': 350,\n",
       " 'cut-rate': 351,\n",
       " 'Sewing': 352,\n",
       " 'faculty': 353,\n",
       " 'tangle': 354,\n",
       " 'rollover': 355,\n",
       " 'arrive': 356,\n",
       " 'sixties': 357,\n",
       " 'affirming': 358,\n",
       " 'estranged': 359,\n",
       " 'horticulturally': 360,\n",
       " '0.31': 361,\n",
       " 'pysllium': 362,\n",
       " 'weighty': 363,\n",
       " 'intelligent': 364,\n",
       " 'buoyancy': 365,\n",
       " 'heckled': 366,\n",
       " 'Reedy': 367,\n",
       " 'courses': 368,\n",
       " 'pampers': 369,\n",
       " 'Pilevsky': 370,\n",
       " 'defraud': 371,\n",
       " 'Nishimura': 372,\n",
       " 'ancillary': 373,\n",
       " 'burdens': 374,\n",
       " 'oasis': 375,\n",
       " 'good-til-canceled': 376,\n",
       " 'Greene': 377,\n",
       " 'counters': 378,\n",
       " 'Verdi': 379,\n",
       " 'example': 380,\n",
       " '212.5': 381,\n",
       " 'herself': 382,\n",
       " 'tenaciously': 383,\n",
       " 'struggled': 384,\n",
       " 'Balzac': 385,\n",
       " 'Fax': 386,\n",
       " '813': 387,\n",
       " 'globe': 388,\n",
       " 'popularized': 389,\n",
       " 'intertwined': 390,\n",
       " 'Shapiro': 391,\n",
       " 'Zombie': 392,\n",
       " 'press': 393,\n",
       " 'run-ins': 394,\n",
       " 'disbanded': 395,\n",
       " 'hand-lotion': 396,\n",
       " '174': 397,\n",
       " 'intertwining': 398,\n",
       " 'quota-trained': 399,\n",
       " 'unamused': 400,\n",
       " 'waive': 401,\n",
       " 'white-washed': 402,\n",
       " 'course-correction': 403,\n",
       " 'traveled': 404,\n",
       " 'Placements': 405,\n",
       " 'Sheremetyevo': 406,\n",
       " 'Cadillac': 407,\n",
       " 'deletions': 408,\n",
       " 'bedroom': 409,\n",
       " 'triangles': 410,\n",
       " 'wagoneer': 411,\n",
       " 'dog-meat': 412,\n",
       " 'intergenerational': 413,\n",
       " 'Somalis': 414,\n",
       " 'Kakumaru': 415,\n",
       " 'spinoffs': 416,\n",
       " 'Crane': 417,\n",
       " 'Fanuc': 418,\n",
       " 'chicken-mutilating': 419,\n",
       " 'colleges': 420,\n",
       " 'Testa': 421,\n",
       " 'Payroll': 422,\n",
       " 'heady': 423,\n",
       " 'hamburger': 424,\n",
       " 'Honeybee': 425,\n",
       " 'indonesian': 426,\n",
       " 'tidy': 427,\n",
       " 'Trish': 428,\n",
       " '99.7': 429,\n",
       " 'Major': 430,\n",
       " 'Toys': 431,\n",
       " 'extramarital': 432,\n",
       " 'administered': 433,\n",
       " 'instinctively': 434,\n",
       " 'undeniably': 435,\n",
       " 'Brothers': 436,\n",
       " '1.4': 437,\n",
       " 'No': 438,\n",
       " 'electrical': 439,\n",
       " 'Amarillo': 440,\n",
       " 'Caucus': 441,\n",
       " 'Comfort': 442,\n",
       " 'cost-of-living': 443,\n",
       " 'multimillion-dollar': 444,\n",
       " 'over': 445,\n",
       " 'Nahas': 446,\n",
       " '8.325': 447,\n",
       " 'specialties': 448,\n",
       " 'banquet-hall': 449,\n",
       " '74.8': 450,\n",
       " 'Denrees': 451,\n",
       " 'reflexively': 452,\n",
       " 'vigor': 453,\n",
       " '4.25': 454,\n",
       " 'tensions': 455,\n",
       " 'divesting': 456,\n",
       " 'spruce': 457,\n",
       " '16.25': 458,\n",
       " 'delivery': 459,\n",
       " '149.3': 460,\n",
       " 'Reproductive': 461,\n",
       " '18.75': 462,\n",
       " '4th': 463,\n",
       " 'couriers': 464,\n",
       " 'Scania': 465,\n",
       " 'archival': 466,\n",
       " 'richmond-area': 467,\n",
       " 'restructurings': 468,\n",
       " 'sell-order': 469,\n",
       " 'sunshine': 470,\n",
       " 'soups': 471,\n",
       " 'mailing': 472,\n",
       " 'kellogg': 473,\n",
       " 'death-backed': 474,\n",
       " 'midnight': 475,\n",
       " 'Veterans': 476,\n",
       " 'advising': 477,\n",
       " '366.85': 478,\n",
       " 'Vahid': 479,\n",
       " 'ubiquitous': 480,\n",
       " 'earth': 481,\n",
       " 'Lyphomed': 482,\n",
       " 'wondered': 483,\n",
       " '65.2': 484,\n",
       " 'canyons': 485,\n",
       " 'peddle': 486,\n",
       " 'elementary': 487,\n",
       " 'conservative-communist': 488,\n",
       " 'decelerated': 489,\n",
       " 'Carney': 490,\n",
       " 'Citibank': 491,\n",
       " 'ineffectual': 492,\n",
       " 'hardball': 493,\n",
       " 'Electrolux': 494,\n",
       " 'unsuccessfully': 495,\n",
       " '7.1': 496,\n",
       " 'waiver': 497,\n",
       " 'Stoltzman': 498,\n",
       " 'spokespersons': 499,\n",
       " 'longshoreman': 500,\n",
       " 'Pine': 501,\n",
       " 'Wilber': 502,\n",
       " 'Lincoln-Mercury-Merkur': 503,\n",
       " 'listings': 504,\n",
       " 'snapshots': 505,\n",
       " 'Tully': 506,\n",
       " 'short-changing': 507,\n",
       " 'presses': 508,\n",
       " 'interleukin-2': 509,\n",
       " 'banker': 510,\n",
       " 'shipments': 511,\n",
       " 'Hammerton': 512,\n",
       " 'ratified': 513,\n",
       " 'County': 514,\n",
       " '36': 515,\n",
       " 'tax': 516,\n",
       " 'Right': 517,\n",
       " 'conceal': 518,\n",
       " 'incongruities': 519,\n",
       " 'high-production': 520,\n",
       " '1263.51': 521,\n",
       " 'abolishing': 522,\n",
       " 'implying': 523,\n",
       " 'readmit': 524,\n",
       " 'a': 525,\n",
       " 'chic': 526,\n",
       " 'status-conscious': 527,\n",
       " '44.50': 528,\n",
       " 'Amityvilles': 529,\n",
       " 'reunification': 530,\n",
       " 'Brophy': 531,\n",
       " 'money': 532,\n",
       " 'Clarke': 533,\n",
       " 'sabers': 534,\n",
       " 'surfaced': 535,\n",
       " 'scimed': 536,\n",
       " 'Mortimer': 537,\n",
       " 'Deloitte': 538,\n",
       " 'Hollingsworth': 539,\n",
       " '335': 540,\n",
       " 'AK-47': 541,\n",
       " 'Cosmetics': 542,\n",
       " 'exclusivity': 543,\n",
       " 'Enfield': 544,\n",
       " 'Halis': 545,\n",
       " 'mother-in-law': 546,\n",
       " 'Declan': 547,\n",
       " 'Suez': 548,\n",
       " '2689.14': 549,\n",
       " 'Sausalito': 550,\n",
       " 'lawful': 551,\n",
       " 'Messinger': 552,\n",
       " 'Gabele': 553,\n",
       " 'pittsburgh-based': 554,\n",
       " 'acclaimed': 555,\n",
       " '354,000': 556,\n",
       " 'deviation': 557,\n",
       " 'arena': 558,\n",
       " 'cracker': 559,\n",
       " 'unify': 560,\n",
       " 'photofinishing': 561,\n",
       " '99.14': 562,\n",
       " 'impressed': 563,\n",
       " 'debtors': 564,\n",
       " 'treasures': 565,\n",
       " 'psychological': 566,\n",
       " 'Halloween': 567,\n",
       " '11,762': 568,\n",
       " 'Diabetes': 569,\n",
       " 'hurricane': 570,\n",
       " 'lender': 571,\n",
       " '20-a-share': 572,\n",
       " '8300': 573,\n",
       " 'auto-dealer': 574,\n",
       " 'bomber': 575,\n",
       " 'conscripts': 576,\n",
       " 'reckoned': 577,\n",
       " 'curious': 578,\n",
       " 'address': 579,\n",
       " 'air-waybill': 580,\n",
       " 'throw': 581,\n",
       " 'collegiate': 582,\n",
       " 'McMillin': 583,\n",
       " '790.2': 584,\n",
       " 'bearable': 585,\n",
       " 'excavated': 586,\n",
       " '757': 587,\n",
       " 'principle': 588,\n",
       " 'corporate-owned': 589,\n",
       " 'mist': 590,\n",
       " 'Assemblyman': 591,\n",
       " '7.05': 592,\n",
       " 'Wine': 593,\n",
       " 'resists': 594,\n",
       " 'jumpy': 595,\n",
       " 'packaging': 596,\n",
       " 'droopy-eyed': 597,\n",
       " 'reimburses': 598,\n",
       " 'Cologne': 599,\n",
       " 'serious': 600,\n",
       " 'discloses': 601,\n",
       " '195.4': 602,\n",
       " 'Boon': 603,\n",
       " 'twisted': 604,\n",
       " 'lumping': 605,\n",
       " 'haul': 606,\n",
       " 'transmission': 607,\n",
       " 'gracious': 608,\n",
       " '40.1': 609,\n",
       " 'Carew': 610,\n",
       " '46.8': 611,\n",
       " 'assassinated': 612,\n",
       " 'feckless': 613,\n",
       " 'pays': 614,\n",
       " '753': 615,\n",
       " 'Challenger': 616,\n",
       " '0.24': 617,\n",
       " '44,400': 618,\n",
       " 'Telzrow': 619,\n",
       " 'prejudices': 620,\n",
       " '18,136': 621,\n",
       " 'researcher': 622,\n",
       " 'bachelor': 623,\n",
       " 'Bowers': 624,\n",
       " 'advanced': 625,\n",
       " '341.16': 626,\n",
       " '44-year-old': 627,\n",
       " 'eventually': 628,\n",
       " 'trust': 629,\n",
       " 'Mich.': 630,\n",
       " 'Nyiregyhaza': 631,\n",
       " 'RMS': 632,\n",
       " 'sexy': 633,\n",
       " '14.28': 634,\n",
       " 'sprinkles': 635,\n",
       " 'Sugar': 636,\n",
       " 'eight-count': 637,\n",
       " 'fending': 638,\n",
       " 'propellant': 639,\n",
       " 'exacerbates': 640,\n",
       " 'Barnabas': 641,\n",
       " 'alienating': 642,\n",
       " '2,600': 643,\n",
       " 'Scurlock': 644,\n",
       " 'inwardly': 645,\n",
       " 'Mines': 646,\n",
       " 'exits': 647,\n",
       " 'Elisabeth': 648,\n",
       " 'segregated': 649,\n",
       " 'epic': 650,\n",
       " 'fiat': 651,\n",
       " 'horsepower': 652,\n",
       " 'anti-science': 653,\n",
       " 'Cawthorn': 654,\n",
       " 'principles': 655,\n",
       " 'Puente': 656,\n",
       " 'Dead': 657,\n",
       " 'flavor': 658,\n",
       " 'Inter': 659,\n",
       " 'workforce': 660,\n",
       " 'Sarasota': 661,\n",
       " 'E.R.': 662,\n",
       " 'absorbed': 663,\n",
       " 'emigration': 664,\n",
       " 'Convex': 665,\n",
       " 'characterizes': 666,\n",
       " 'volcano': 667,\n",
       " 'Crash': 668,\n",
       " 'high-yield': 669,\n",
       " 'invent': 670,\n",
       " 'dispense': 671,\n",
       " 'straining': 672,\n",
       " 'vacating': 673,\n",
       " 'builds': 674,\n",
       " 'Sigoloff': 675,\n",
       " 'Harlan': 676,\n",
       " 'townhouses': 677,\n",
       " 'skill': 678,\n",
       " 'flotations': 679,\n",
       " 'Triborough': 680,\n",
       " 'Fredric': 681,\n",
       " 'Buksbaum': 682,\n",
       " 'berated': 683,\n",
       " 'discover': 684,\n",
       " 'Roebuck': 685,\n",
       " 'sits': 686,\n",
       " '1,838,200': 687,\n",
       " 'Southport': 688,\n",
       " 'feline': 689,\n",
       " 'publication': 690,\n",
       " 'embassy': 691,\n",
       " 'shakespeare': 692,\n",
       " 'payables': 693,\n",
       " 'symbolism': 694,\n",
       " 'Electrical': 695,\n",
       " 'capitalist': 696,\n",
       " 'forgot': 697,\n",
       " 'american-made': 698,\n",
       " 'higher-quality': 699,\n",
       " 'Teresa': 700,\n",
       " 'arbitrage': 701,\n",
       " 'water-submersion': 702,\n",
       " 'Oil': 703,\n",
       " '33,000': 704,\n",
       " 'selections': 705,\n",
       " 'ancient': 706,\n",
       " 'applaud': 707,\n",
       " 'faking': 708,\n",
       " 'derail': 709,\n",
       " 'hay': 710,\n",
       " 'accompanied': 711,\n",
       " 'krater': 712,\n",
       " 'guesswork': 713,\n",
       " 'doubly': 714,\n",
       " 'wrested': 715,\n",
       " 'unsubsidized': 716,\n",
       " 'Sabina': 717,\n",
       " 'streets': 718,\n",
       " 'Omega': 719,\n",
       " 'Valu': 720,\n",
       " 'socialism': 721,\n",
       " 'Wah': 722,\n",
       " 'Proleukin': 723,\n",
       " 'uttering': 724,\n",
       " '1986': 725,\n",
       " 'racism': 726,\n",
       " 'juries': 727,\n",
       " 'memorabilia': 728,\n",
       " 'Adamski': 729,\n",
       " 'yearbook': 730,\n",
       " 'eyeballing': 731,\n",
       " 'moonie': 732,\n",
       " 'newsweekly': 733,\n",
       " 'Christ': 734,\n",
       " 'withdrawal': 735,\n",
       " 'randomly': 736,\n",
       " 'XR4Ti': 737,\n",
       " 'visited': 738,\n",
       " 'four-stroke': 739,\n",
       " 'blotting': 740,\n",
       " 'candles': 741,\n",
       " 'billionnaire': 742,\n",
       " 'retail': 743,\n",
       " 'Koerner': 744,\n",
       " 'profligate': 745,\n",
       " 'Lindner': 746,\n",
       " 'Testing': 747,\n",
       " 'cancer-suppressing': 748,\n",
       " 'Ticor': 749,\n",
       " 'hazelnut': 750,\n",
       " '51-cash': 751,\n",
       " 'coniston': 752,\n",
       " 'ubiquity': 753,\n",
       " 'jackals': 754,\n",
       " 'Asset': 755,\n",
       " 'lingering': 756,\n",
       " 'Rash': 757,\n",
       " 'rescind': 758,\n",
       " 'complicity': 759,\n",
       " '34-foot-tall': 760,\n",
       " 'accountants': 761,\n",
       " 'prowess': 762,\n",
       " 'mythic': 763,\n",
       " 'shortages': 764,\n",
       " 'lilting': 765,\n",
       " 'commented': 766,\n",
       " '324': 767,\n",
       " 'Stouffer': 768,\n",
       " 'distributors': 769,\n",
       " 'intermixed': 770,\n",
       " 'scenes': 771,\n",
       " 'cement-mixing': 772,\n",
       " 'personal-computer': 773,\n",
       " 'cheese': 774,\n",
       " 'temporarily': 775,\n",
       " 'Willie': 776,\n",
       " 'periodically': 777,\n",
       " '159': 778,\n",
       " 'Higher': 779,\n",
       " 'Mogadishu': 780,\n",
       " 'Plymouth': 781,\n",
       " 'Homeless': 782,\n",
       " 'Betty': 783,\n",
       " 'Hibler': 784,\n",
       " '411': 785,\n",
       " '10-month': 786,\n",
       " 'Facility': 787,\n",
       " 'extraordinary': 788,\n",
       " 'posting': 789,\n",
       " 'unveil': 790,\n",
       " 'divers': 791,\n",
       " 'Birney': 792,\n",
       " 'zero-inflation': 793,\n",
       " 'roadbed': 794,\n",
       " 'indian': 795,\n",
       " 'Turtles': 796,\n",
       " 'investigator': 797,\n",
       " 'Ritterman': 798,\n",
       " 'small-fry': 799,\n",
       " '2791.41': 800,\n",
       " 'dollar': 801,\n",
       " 'arsenals': 802,\n",
       " 'two-time': 803,\n",
       " 'Housing': 804,\n",
       " 'fanny': 805,\n",
       " 'interior': 806,\n",
       " 'Pilson': 807,\n",
       " 'maxim': 808,\n",
       " 'Fox-Meyer': 809,\n",
       " 'windows': 810,\n",
       " 'milwaukee-based': 811,\n",
       " 'Bacarella': 812,\n",
       " '357.4': 813,\n",
       " 'venerable': 814,\n",
       " 'robbing': 815,\n",
       " '12,252': 816,\n",
       " '101,250': 817,\n",
       " '85.8': 818,\n",
       " 'oppression': 819,\n",
       " 'Mesa': 820,\n",
       " 'biographer': 821,\n",
       " '7': 822,\n",
       " 'delicately': 823,\n",
       " 'jugglers': 824,\n",
       " 'planet': 825,\n",
       " 'Tracers': 826,\n",
       " '128.19': 827,\n",
       " 'verifiable': 828,\n",
       " 'sciences': 829,\n",
       " 'vicars': 830,\n",
       " 'spearheading': 831,\n",
       " 'black-draped': 832,\n",
       " 'Names': 833,\n",
       " 'implicate': 834,\n",
       " 'stint': 835,\n",
       " 'slipshod': 836,\n",
       " 'Kirghiz': 837,\n",
       " 'Vandenberg': 838,\n",
       " 'Soichiro': 839,\n",
       " 'tick': 840,\n",
       " 'territory': 841,\n",
       " 'Lep': 842,\n",
       " 'Naomi': 843,\n",
       " 'turned': 844,\n",
       " 'paraphernalia': 845,\n",
       " 'Itel': 846,\n",
       " 'city-wide': 847,\n",
       " 'law-governed': 848,\n",
       " 'begins': 849,\n",
       " 'over-optimistic': 850,\n",
       " 'staff': 851,\n",
       " 'Sr.': 852,\n",
       " 'pre-strike': 853,\n",
       " 'capital-punishment': 854,\n",
       " 'Gilgore': 855,\n",
       " 'Hotels': 856,\n",
       " 'herring': 857,\n",
       " 'venal': 858,\n",
       " 'constructively': 859,\n",
       " 'hardware': 860,\n",
       " 'Lyon': 861,\n",
       " 'knows': 862,\n",
       " 'cyclical': 863,\n",
       " 'MPD': 864,\n",
       " 'classical-music': 865,\n",
       " '2,888,000': 866,\n",
       " 'Langendorf': 867,\n",
       " 'yankee': 868,\n",
       " 'EXXON': 869,\n",
       " 'environment': 870,\n",
       " 'salad': 871,\n",
       " 'rewrapped': 872,\n",
       " 'unrealized': 873,\n",
       " 'Greenwood': 874,\n",
       " 'Mountains': 875,\n",
       " 'analogous': 876,\n",
       " 'Open': 877,\n",
       " 'hunting': 878,\n",
       " 'Eurodollar': 879,\n",
       " 'whiner': 880,\n",
       " 'wholly': 881,\n",
       " '7.32': 882,\n",
       " 'skillful': 883,\n",
       " '219.19': 884,\n",
       " 'chasing': 885,\n",
       " 'reiterating': 886,\n",
       " 'disinterested': 887,\n",
       " 'Parts': 888,\n",
       " 'indicators': 889,\n",
       " 'rematch': 890,\n",
       " 'Phelan': 891,\n",
       " '792': 892,\n",
       " 'R.I.': 893,\n",
       " 'shells': 894,\n",
       " '5.58': 895,\n",
       " 'dissuade': 896,\n",
       " '500-store': 897,\n",
       " 'Rochester': 898,\n",
       " 'underperformed': 899,\n",
       " 'gratuities': 900,\n",
       " 'executed': 901,\n",
       " 'abandons': 902,\n",
       " '861': 903,\n",
       " 'roars': 904,\n",
       " 'Connoisseur': 905,\n",
       " 'servers': 906,\n",
       " 'platter': 907,\n",
       " 'costing': 908,\n",
       " 'Refinery': 909,\n",
       " '160,000': 910,\n",
       " 'near-record': 911,\n",
       " 'Ferembal': 912,\n",
       " 'spilling': 913,\n",
       " 'Playhouse': 914,\n",
       " 'calculations': 915,\n",
       " 'disdaining': 916,\n",
       " 'petitioned': 917,\n",
       " 'desultory': 918,\n",
       " 'shambles': 919,\n",
       " 'supply-sider': 920,\n",
       " 'purports': 921,\n",
       " 'manipulating': 922,\n",
       " 'Refcorp': 923,\n",
       " 'Record': 924,\n",
       " 'rigorous': 925,\n",
       " 'slats': 926,\n",
       " 'sacking': 927,\n",
       " 'discrete': 928,\n",
       " 'finals': 929,\n",
       " 'skim': 930,\n",
       " 'cripples': 931,\n",
       " 'short-selling': 932,\n",
       " 'fledgling': 933,\n",
       " 'Warner': 934,\n",
       " 'paring': 935,\n",
       " 'Packwood': 936,\n",
       " 'Bebear': 937,\n",
       " '23.31': 938,\n",
       " 'Alurralde': 939,\n",
       " 'trio': 940,\n",
       " 'exploiting': 941,\n",
       " 'P.J.': 942,\n",
       " 'movieland': 943,\n",
       " 'regulation': 944,\n",
       " 'outlay': 945,\n",
       " 'fidgeting': 946,\n",
       " 'friers': 947,\n",
       " 'Sajak': 948,\n",
       " 'cheetah': 949,\n",
       " 'smaller-size': 950,\n",
       " '1989-90': 951,\n",
       " 'server': 952,\n",
       " '6.5': 953,\n",
       " 'testers': 954,\n",
       " 'answering': 955,\n",
       " 'apparently': 956,\n",
       " 'autonomy': 957,\n",
       " 'rook': 958,\n",
       " 'consumption': 959,\n",
       " 'Ski': 960,\n",
       " 'well-intended': 961,\n",
       " 'base-price': 962,\n",
       " 'u.s.-style': 963,\n",
       " 'biomedical-products': 964,\n",
       " 'age-specific': 965,\n",
       " 'hemoglobin': 966,\n",
       " 'patrons': 967,\n",
       " 'comparatively': 968,\n",
       " 'syndicates': 969,\n",
       " 'L.J.': 970,\n",
       " 'parted': 971,\n",
       " 'Bucaramanga': 972,\n",
       " 'Tripoli': 973,\n",
       " 'rescissions': 974,\n",
       " 'pilot-seniority': 975,\n",
       " 'DEPOSIT': 976,\n",
       " 'pertinent': 977,\n",
       " 'endlessly': 978,\n",
       " 'Multilateral': 979,\n",
       " '3636.06': 980,\n",
       " 'powered': 981,\n",
       " 'Pale': 982,\n",
       " 'Pool': 983,\n",
       " 'ba-3': 984,\n",
       " 'aspirations': 985,\n",
       " 'MeraBank': 986,\n",
       " 'sink': 987,\n",
       " 'uniquely': 988,\n",
       " 'banning': 989,\n",
       " 'purely': 990,\n",
       " '361,000': 991,\n",
       " 'psychoanalyst': 992,\n",
       " 'sifted': 993,\n",
       " 'steadied': 994,\n",
       " 'match': 995,\n",
       " 'gratuity': 996,\n",
       " '211.96': 997,\n",
       " 'quick-service': 998,\n",
       " 'coffee-shop': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PDT': 0,\n",
       " '#': 1,\n",
       " 'NN': 2,\n",
       " 'WDT': 3,\n",
       " 'JJR': 4,\n",
       " 'JJS': 5,\n",
       " '.': 6,\n",
       " 'CD': 7,\n",
       " 'MD': 8,\n",
       " '``': 9,\n",
       " 'LS': 10,\n",
       " 'CC': 11,\n",
       " 'TO': 12,\n",
       " '$': 13,\n",
       " 'JJ': 14,\n",
       " 'VBD': 15,\n",
       " 'PRP$': 16,\n",
       " \"''\": 17,\n",
       " 'PRP': 18,\n",
       " 'RBS': 19,\n",
       " 'SYM': 20,\n",
       " 'VBZ': 21,\n",
       " 'WP$': 22,\n",
       " 'UH': 23,\n",
       " 'POS': 24,\n",
       " 'RB': 25,\n",
       " ':': 26,\n",
       " '-LRB-': 27,\n",
       " 'VB': 28,\n",
       " 'EX': 29,\n",
       " 'DT': 30,\n",
       " '-RRB-': 31,\n",
       " 'VBP': 32,\n",
       " 'WP': 33,\n",
       " 'NNS': 34,\n",
       " 'NNPS': 35,\n",
       " 'RP': 36,\n",
       " 'FW': 37,\n",
       " 'NNP': 38,\n",
       " 'RBR': 39,\n",
       " 'VBN': 40,\n",
       " 'WRB': 41,\n",
       " 'VBG': 42,\n",
       " ',': 43,\n",
       " 'IN': 44}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_len = 50\n",
    "X = [[word2id[w[0]] for w in s] for s in sentencas_treino]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=len(palavras)-1)\n",
    "y = [[tag2id[w[1]] for w in s] for s in sentencas_treino]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2id[\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=len(tags)) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9561, 41022, 40239, 20522,  8485, 23330, 40239, 37455, 44335,\n",
       "       17736, 28894, 30439,   525, 10816,  9249, 21793,  3475, 36968,\n",
       "       47343, 47343, 47343, 47343, 47343, 47343, 47343, 47343, 47343,\n",
       "       47343, 47343, 47343, 47343, 47343, 47343, 47343, 47343, 47343,\n",
       "       47343, 47343, 47343, 47343, 47343, 47343, 47343, 47343, 47343,\n",
       "       47343, 47343, 47343, 47343, 47343], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separação em conjunto de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição de arquiteturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_uni = Input(shape=(max_len,)) # Camada de Input\n",
    "modelo_uni = Embedding(input_dim=len(palavras), output_dim=100, input_length=max_len)(input_uni) # Camada de Word embedding com dimensão maior\n",
    "modelo_uni = Dropout(0.2)(modelo_uni) # Camada de Dropout com taxa menor\n",
    "modelo_uni = LSTM(units=64, return_sequences=True, recurrent_dropout=0.2)(modelo_uni) # Camada de LSTM unidirecional com mais unidades\n",
    "modelo_uni = Dropout(0.3)(modelo_uni) # Camada de Dropout adicional\n",
    "modelo_uni = LSTM(units=32, return_sequences=True, recurrent_dropout=0.1)(modelo_uni) # Segunda camada LSTM com menos unidades\n",
    "modelo_uni = Dense(128, activation='relu')(modelo_uni) # Camada densa intermediária\n",
    "modelo_uni = Dropout(0.2)(modelo_uni) # Dropout após camada densa\n",
    "out_uni = TimeDistributed(Dense(len(tags), activation=\"softmax\"))(modelo_uni)  # Camada de softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_uni = Model(input_uni, out_uni) # Modelo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,734,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,805</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m4,734,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m42,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m45\u001b[0m)         │         \u001b[38;5;34m5,805\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,799,085</span> (18.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,799,085\u001b[0m (18.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,799,085</span> (18.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,799,085\u001b[0m (18.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_uni.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_uni.compile(\n",
    "    optimizer=\"rmsprop\", \n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 63ms/step - accuracy: 0.6655 - loss: 1.2249 - val_accuracy: 0.9187 - val_loss: 0.3035\n",
      "Epoch 2/3\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 61ms/step - accuracy: 0.9199 - loss: 0.2850 - val_accuracy: 0.9637 - val_loss: 0.1324\n",
      "Epoch 3/3\n",
      "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 61ms/step - accuracy: 0.9605 - loss: 0.1403 - val_accuracy: 0.9699 - val_loss: 0.1045\n"
     ]
    }
   ],
   "source": [
    "history = modelo_uni.fit(X_tr, \n",
    "    np.array(y_tr),\n",
    "    batch_size=32, \n",
    "    epochs=3, \n",
    "    validation_split=0.2, \n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salvar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "with open('lstm_uni_model_1.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo_uni, f)\n",
    "\n",
    "print(\"Modelo salvo com sucesso em 'lstm_uni_model_1.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testes demonstrativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1213\n",
    "p = modelo_uni.predict(np.array([X_te[i]])) # Predição\n",
    "p = np.argmax(p, axis=-1) # Mapear softmax de volta para um índice POS\n",
    "for w, pred in zip(X_te[i], p[0]): # Para cada palavra na sentença\n",
    "    print(\"{:20} -- {}\".format(palavras[w], tags[pred])) # Imprimir palavra e tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentenca = word_tokenize('That was a nice jump')\n",
    "# Substituir palavras desconhecidas pelo índice da palavra desconhecida\n",
    "X_Samp = pad_sequences(maxlen=max_len, sequences=[[word2id.get(word, len(palavras)-1) for word in sentenca]], padding=\"post\", value=len(palavras)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = modelo_uni.predict(np.array([X_Samp[0]])) # Predict on it\n",
    "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
    "for w, pred in zip(X_Samp[0], p[0]): # for every word in the sentence\n",
    "    print(\"{:20} -- {}\".format(palavras[w], tags[pred])) # Print word and tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bi = Input(shape=(max_len,)) # Camada de Input\n",
    "modelo_bi = Embedding(input_dim=len(palavras), output_dim=50, input_length=max_len)(input_bi) # Camada de Word embedding\n",
    "modelo_bi = Dropout(0.3)(modelo_bi) # Camada de Dropout\n",
    "modelo_bi = Bidirectional(LSTM(units=50, return_sequences=True, recurrent_dropout=0.1))(modelo_bi) # Camada de Bidirectional LSTM\n",
    "out_bi = TimeDistributed(Dense(len(tags), activation=\"softmax\"))(modelo_bi)  # Camada de softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_bi = Model(input_bi, out_bi) # Modelo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,367,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │     \u001b[38;5;34m2,367,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m40,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m45\u001b[0m)         │         \u001b[38;5;34m4,545\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,412,145</span> (9.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,412,145\u001b[0m (9.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,412,145</span> (9.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,412,145\u001b[0m (9.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo_bi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_bi.compile(\n",
    "    optimizer=\"rmsprop\", \n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1969/1969\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 33ms/step - accuracy: 0.7756 - loss: 0.8499 - val_accuracy: 0.9650 - val_loss: 0.1230\n",
      "Epoch 2/3\n",
      "\u001b[1m1969/1969\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 31ms/step - accuracy: 0.9680 - loss: 0.1124 - val_accuracy: 0.9759 - val_loss: 0.0822\n",
      "Epoch 3/3\n",
      "\u001b[1m1969/1969\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 32ms/step - accuracy: 0.9780 - loss: 0.0757 - val_accuracy: 0.9789 - val_loss: 0.0698\n"
     ]
    }
   ],
   "source": [
    "history = modelo_bi.fit(X_tr, \n",
    "    np.array(y_tr), \n",
    "    batch_size=16, \n",
    "    epochs=3, \n",
    "    validation_split=0.2, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salvar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo com sucesso em 'lstm_model_1.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "with open('lstm_bi_model_1.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo_bi, f)\n",
    "\n",
    "print(\"Modelo salvo com sucesso em 'lstm_bi_model_1.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testes demonstrativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678ms/step\n",
      "the                  -- DT\n",
      "two                  -- CD\n",
      "men                  -- NNS\n",
      "are                  -- VBP\n",
      "longtime             -- JJ\n",
      "friends              -- NNS\n",
      "and                  -- CC\n",
      "tennis               -- NN\n",
      "partners             -- NNS\n",
      ",                    -- ,\n",
      "having               -- VBG\n",
      "met                  -- VBN\n",
      "about                -- IN\n",
      "25                   -- CD\n",
      "years                -- NNS\n",
      "ago                  -- RB\n",
      ".                    -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n"
     ]
    }
   ],
   "source": [
    "i = 1213\n",
    "p = modelo_bi.predict(np.array([X_te[i]])) # Predição\n",
    "p = np.argmax(p, axis=-1) # Mapear softmax de volta para um índice POS\n",
    "for w, pred in zip(X_te[i], p[0]): # Para cada palavra na sentença\n",
    "    print(\"{:20} -- {}\".format(palavras[w], tags[pred])) # Imprimir palavra e tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Teste com sentença aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentenca = word_tokenize('That was a nice jump')\n",
    "# Substituir palavras desconhecidas pelo índice da palavra desconhecida\n",
    "X_Samp = pad_sequences(maxlen=max_len, sequences=[[word2id.get(word, len(palavras)-1) for word in sentenca]], padding=\"post\", value=len(palavras)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "<PAD>                -- .\n",
      "was                  -- VBD\n",
      "a                    -- DT\n",
      "nice                 -- JJ\n",
      "jump                 -- NN\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n",
      "<PAD>                -- .\n"
     ]
    }
   ],
   "source": [
    "p = modelo_bi.predict(np.array([X_Samp[0]])) # Predict on it\n",
    "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
    "for w, pred in zip(X_Samp[0], p[0]): # for every word in the sentence\n",
    "    print(\"{:20} -- {}\".format(palavras[w], tags[pred])) # Print word and tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
